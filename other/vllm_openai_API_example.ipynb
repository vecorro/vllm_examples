{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Must provide an 'engine' or 'model' parameter to create a <class 'openai.api_resources.completion.Completion'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m openai\u001B[38;5;241m.\u001B[39mapi_base \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp://172.29.214.18:8000/v1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Send the completion request using custom parameters\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m completion \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;66;43;03m#model=\"tiiuae/falcon-7b\",\u001B[39;49;00m\n\u001B[1;32m     19\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHow do I cook fried rice?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Print the prompt completion results\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(completion\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtext)\n",
      "File \u001B[0;32m~/miniconda3/envs/falcon/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001B[0m, in \u001B[0;36mCompletion.create\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[0;32m~/miniconda3/envs/falcon/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:149\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    137\u001B[0m ):\n\u001B[1;32m    138\u001B[0m     (\n\u001B[1;32m    139\u001B[0m         deployment_id,\n\u001B[1;32m    140\u001B[0m         engine,\n\u001B[1;32m    141\u001B[0m         timeout,\n\u001B[1;32m    142\u001B[0m         stream,\n\u001B[1;32m    143\u001B[0m         headers,\n\u001B[1;32m    144\u001B[0m         request_timeout,\n\u001B[1;32m    145\u001B[0m         typed_api_type,\n\u001B[1;32m    146\u001B[0m         requestor,\n\u001B[1;32m    147\u001B[0m         url,\n\u001B[1;32m    148\u001B[0m         params,\n\u001B[0;32m--> 149\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__prepare_create_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_base\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_version\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morganization\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m requestor\u001B[38;5;241m.\u001B[39mrequest(\n\u001B[1;32m    154\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    155\u001B[0m         url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[1;32m    161\u001B[0m     )\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/falcon/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:90\u001B[0m, in \u001B[0;36mEngineAPIResource.__prepare_create_request\u001B[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001B[0m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m engine \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 90\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mInvalidRequestError(\n\u001B[1;32m     91\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust provide an \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mengine\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m parameter to create a \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     92\u001B[0m             \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m     93\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     94\u001B[0m         )\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;66;03m# No special timeout handling\u001B[39;00m\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[0;31mInvalidRequestError\u001B[0m: Must provide an 'engine' or 'model' parameter to create a <class 'openai.api_resources.completion.Completion'>"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\"\"\"\n",
    "First you need to run an OpenAI-compatible service using vLLM. For instance,\n",
    "the following command serves the Falcon-7b model on URL http://127.0.0.1:8000/v1\n",
    "\n",
    "python -m vllm.entrypoints.openai.api_server --model tiiuae/falcon-7b --trust-remote-code\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai.api_key = \"EMPTY\"\n",
    "\n",
    "# Define the service URL\n",
    "openai.api_base = \"http://172.29.214.18:8000/v1\"\n",
    "\n",
    "# Send the completion request using custom parameters\n",
    "completion = openai.Completion.create(model=\"tiiuae/falcon-7b\",\n",
    "                                      prompt=\"How do I cook fried rice?\",\n",
    "                                      temperature=0.3,\n",
    "                                      max_tokens=128,\n",
    "                                      )\n",
    "# Print the prompt completion results\n",
    "print(completion.choices[0].text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T14:32:44.684270393Z",
     "start_time": "2023-08-05T14:32:42.508623232Z"
    }
   },
   "id": "521ca48691b42249"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
